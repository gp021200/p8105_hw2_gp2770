p8105_hw2_gp2770
================
Gokul Pareek
2024-10-03

I’m an R Markdown document!

# Problem 1

Reading and Cleaning the Data

``` r
library (tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.1     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.3     ✔ tidyr     1.3.1
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
nyc_transit_data <- read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",col_types= cols(Route8 = "c", Route9 = "c",Route10 = "c",Route11 = "c")) %>%   janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude,route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

nyc_transit_data
```

    ## # A tibble: 1,868 × 19
    ##    line     station_name station_latitude station_longitude route1 route2 route3
    ##    <chr>    <chr>                   <dbl>             <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  2 4 Avenue 25th St                  40.7             -74.0 R      <NA>   <NA>  
    ##  3 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  4 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  5 4 Avenue 36th St                  40.7             -74.0 N      R      <NA>  
    ##  6 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  7 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  8 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ##  9 4 Avenue 45th St                  40.6             -74.0 R      <NA>   <NA>  
    ## 10 4 Avenue 53rd St                  40.6             -74.0 R      <NA>   <NA>  
    ## # ℹ 1,858 more rows
    ## # ℹ 12 more variables: route4 <chr>, route5 <chr>, route6 <chr>, route7 <chr>,
    ## #   route8 <chr>, route9 <chr>, route10 <chr>, route11 <chr>, entry <lgl>,
    ## #   vending <chr>, entrance_type <chr>, ada <lgl>

The resulting dataset contains information about each entrance and exit
for each subway station in NYC, including details such as the subway
line, station name, geographic coordinates, routes served, entrance
type, and ADA compliance status. Till now, I have standardized the
variable names by converting them to lower snake case, selected and
retained the relevant variables, and recoded the entry variable from a
character class with “YES” and “NO” values to a logical class with
“TRUE” and “FALSE” values. The dataset currently has 1,868 rows and 19
columns. However, the data is not yet tidy, as the multiple columns for
route numbers (routes 1 through 11) represent values themselves, rather
than being captured as a single variable.

Finding the number of distinct stations

``` r
nrow(distinct(nyc_transit_data, line, station_name))
```

    ## [1] 465

There are 465 distinct stations.

ADA compliant stations

``` r
nyc_transit_data %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 84

Out of the 465 distinct stations, 84 stations are ADA compliant.

Proportion of station entrances/exits without vending that allow
entrance

``` r
without_vending <- nyc_transit_data %>% 
                    filter(vending == "NO") %>%
                    filter(entry == TRUE) %>%  
                    nrow()

with_vending <- nyc_transit_data %>% 
                  filter(vending == "NO") %>%
                  nrow()

without_vending / with_vending
```

    ## [1] 0.3770492

0.377 is the proportion of station entrances/exits without vending that
allow entrances.

Reformatting the data to make route number and route name distinct
variables

``` r
nyc_transit_reformat_data <- nyc_transit_data %>%
  pivot_longer(route1:route11, 
               names_to = "route_number", 
               values_to = "route_name")

nyc_transit_reformat_data
```

    ## # A tibble: 20,548 × 10
    ##    line     station_name station_latitude station_longitude entry vending
    ##    <chr>    <chr>                   <dbl>             <dbl> <lgl> <chr>  
    ##  1 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  2 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  3 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  4 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  5 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  6 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  7 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  8 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ##  9 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## 10 4 Avenue 25th St                  40.7             -74.0 TRUE  YES    
    ## # ℹ 20,538 more rows
    ## # ℹ 4 more variables: entrance_type <chr>, ada <lgl>, route_number <chr>,
    ## #   route_name <chr>

Distinct stations that serve the A train

``` r
nyc_transit_reformat_data %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 60

60 distinct stations serve the A train.

A train serving stations that are ADA compliant

``` r
nyc_transit_reformat_data %>% 
  filter(ada == TRUE) %>%  
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

    ## [1] 17

Of the 60 stations that serve the A train, 17 stations are ADA
compliant.

# Problem 2

Reading and Cleaning the Mr. Trash Wheel sheet

``` r
library(readxl)

mr_trash_wheel_data <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx",                           sheet = "Mr. Trash Wheel",range =  cell_cols("A:N"), 
                        col_names = TRUE, skip = 1) %>%
  janitor::clean_names() %>%
  rename(
    collection_month = month,
    collection_year = year,
    plastic_bottles_collected = plastic_bottles,
    polystyrene_collected = polystyrene,
    cigarette_butts_collected = cigarette_butts,
    sports_balls_collected = sports_balls,
    glass_bottles_collected = glass_bottles,
    wrappers_collected = wrappers,
    plastic_bags_collected = plastic_bags
    )%>%
  filter(!is.na(dumpster)) %>%
  mutate(
    sports_balls_collected = as.integer(round(sports_balls_collected)),
    trash_wheel = "Mr. Trash Wheel"
  )
```

Reading and Cleaning the Professor Trash Wheel

``` r
professor_trash_wheel_data <-  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = cell_cols("A:M"), col_names = TRUE, skip = 1) %>%
  janitor::clean_names() %>%
  rename(
    collection_month = month,
    collection_year = year,
    plastic_bottles_collected = plastic_bottles,
    polystyrene_collected = polystyrene,
    cigarette_butts_collected = cigarette_butts,
    glass_bottles_collected = glass_bottles,
    wrappers_collected = wrappers,
    plastic_bags_collected = plastic_bags
    )%>%
  filter(!is.na(dumpster)) %>%
  mutate(trash_wheel = "Professor Trash Wheel"
  )
```

Reading and Cleaning the Gwynnda Trash Wheel

``` r
gwynnda_trash_wheel_data <-  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = cell_cols("A:L"), col_names = TRUE, skip = 1) %>%
  janitor::clean_names() %>%
  rename(
    collection_month = month,
    collection_year = year,
    plastic_bottles_collected = plastic_bottles,
    polystyrene_collected = polystyrene,
    cigarette_butts_collected = cigarette_butts,
    wrappers_collected = wrappers,
    plastic_bags_collected = plastic_bags
    )%>%
  filter(!is.na(dumpster)) %>%
  mutate(trash_wheel = "Gwynnda Trash Wheel"
  )
```

Combining the three datasets

``` r
mr_trash_wheel_data <- mr_trash_wheel_data %>%
  mutate(collection_year = as.character(collection_year))

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  mutate(collection_year = as.character(collection_year))

gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  mutate(collection_year = as.character(collection_year))

combined_trash_wheel_data <- bind_rows(mr_trash_wheel_data, 
                                       professor_trash_wheel_data, 
                                       gwynnda_trash_wheel_data)

combined_trash_wheel_data
```

    ## # A tibble: 1,033 × 15
    ##    dumpster collection_month collection_year date                weight_tons
    ##       <dbl> <chr>            <chr>           <dttm>                    <dbl>
    ##  1        1 May              2014            2014-05-16 00:00:00        4.31
    ##  2        2 May              2014            2014-05-16 00:00:00        2.74
    ##  3        3 May              2014            2014-05-16 00:00:00        3.45
    ##  4        4 May              2014            2014-05-17 00:00:00        3.1 
    ##  5        5 May              2014            2014-05-17 00:00:00        4.06
    ##  6        6 May              2014            2014-05-20 00:00:00        2.71
    ##  7        7 May              2014            2014-05-21 00:00:00        1.91
    ##  8        8 May              2014            2014-05-28 00:00:00        3.7 
    ##  9        9 June             2014            2014-06-05 00:00:00        2.52
    ## 10       10 June             2014            2014-06-11 00:00:00        3.76
    ## # ℹ 1,023 more rows
    ## # ℹ 10 more variables: volume_cubic_yards <dbl>,
    ## #   plastic_bottles_collected <dbl>, polystyrene_collected <dbl>,
    ## #   cigarette_butts_collected <dbl>, glass_bottles_collected <dbl>,
    ## #   plastic_bags_collected <dbl>, wrappers_collected <dbl>,
    ## #   sports_balls_collected <int>, homes_powered <dbl>, trash_wheel <chr>

The combined Trash Wheel dataset contains a total of 1033 observations,
consolidating information from three different Trash Wheels: Mr. Trash
Wheel, Professor Trash Wheel, and Gwynnda. Key variables include
collection_month, collection_year, weight_tons which is the weight of
trash collected by each dumpster, and waste types like
cigarette_butts_collected and plastic_bags_collected.

Total weight of trash collected by Professor Trash Wheel

``` r
total_professor_trash_wheel_weight <- combined_trash_wheel_data %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  pull(weight_tons) %>%
  sum(na.rm = TRUE)

total_professor_trash_wheel_weight
```

    ## [1] 246.74

The total weight of trash collected by Professor Trash Wheel was 246.74
tons.

Total number of cigarette butts collected by Gwynnda in June of 2022

``` r
total_cigarette_butts_gwynnda_june_2022 <- combined_trash_wheel_data %>%
  filter(trash_wheel == "Gwynnda Trash Wheel" & collection_month == "June" & collection_year == 2022) %>%
  pull(cigarette_butts_collected) %>%
  sum(na.rm = TRUE)

total_cigarette_butts_gwynnda_june_2022
```

    ## [1] 18120

The total number of cigarette butts collected by Gwynnda in June of 2022
was 18120.

# Problem 3

Importing and cleaning the information about individual bakers, their
bakes and their performances.

``` r
bakers <- read_csv("./data/bakers.csv", na = c("NA", "",".")) %>% 
  janitor::clean_names() %>% 
  separate(col = baker_name, into = c("baker", "baker_last_name"), sep = " ")
```

    ## Rows: 120 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker Name, Baker Occupation, Hometown
    ## dbl (2): Series, Baker Age
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bakes <- read_csv("./data/bakes.csv", na = c("NA", "",".")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = ifelse(baker == '"Jo"', "Joanne", baker))
```

    ## Rows: 548 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (3): Baker, Signature Bake, Show Stopper
    ## dbl (2): Series, Episode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
results <- read_csv("./data/results.csv", skip = 2, na = c("NA", "",".")) %>% 
  janitor::clean_names()
```

    ## Rows: 1136 Columns: 5
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (2): baker, result
    ## dbl (3): series, episode, technical
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Checking for completeness and correctness across datasets.

``` r
missing_bakes = anti_join(bakers, bakes, 
                              by = c("baker" = "baker", "series"))

missing_results = anti_join(bakers, results, 
                                by = c("baker" = "baker", "series"))

missing_bakes_results = anti_join(bakes, results, 
                                          by = c("baker", "series", "episode"))
```

Creating a single final dataset and exporting the results as a CSV.

``` r
final_dataset = left_join(results, bakes, by = c("series", "episode", "baker")) %>% 
                  left_join(bakers, by = c("series", "baker"))

final_dataset <- final_dataset %>%
  relocate(series, episode, baker, baker_last_name, baker_age, baker_occupation, hometown, signature_bake, technical, show_stopper, result)

write_csv(final_dataset, "./data/final_gbbo_dataset.csv")
```

In the data cleaning process, I imported three datasets of the Great
British Bake Off —bakers, bakes, and results while standardizing their
column names using janitor::clean_names(). I separated the baker_name
into distinct first and last names and modified specific values for
consistency (changing “Jo” to “Joanne” in the bakes dataset). I skipped
unnecessary rows in the results dataset and checked for completeness
using anti_join() to identify missing matches across the datasets. The
final dataset was created by merging the three datasets based on common
columns and relocating the columns for clarity. Finally, I used
write_csv() to export the cleaned and combined dataset as a CSV file
named final_gbbo_dataset.csv in the data directory. The final dataset
gives a comprehensive overview of the Great British Bake Off (GBBO)
competition, combining individual baker details with their bakes and
performance results. Important variables are like series, episode, baker
and show_stopper are relocated in order to conduct smooth analysis on
the consolidated dataset.

Creating a reader-friendly table for star baker/winner of each episode
from S5 to S10.

``` r
star_bakers_or_winners <- final_dataset %>%
  filter(series > 4) %>%  
  select(series, episode, baker, result) %>%
  filter(result %in% c("STAR BAKER", "WINNER")) %>%
  arrange(series, episode) 

star_bakers_or_winners
```

    ## # A tibble: 60 × 4
    ##    series episode baker   result    
    ##     <dbl>   <dbl> <chr>   <chr>     
    ##  1      5       1 Nancy   STAR BAKER
    ##  2      5       2 Richard STAR BAKER
    ##  3      5       3 Luis    STAR BAKER
    ##  4      5       4 Richard STAR BAKER
    ##  5      5       5 Kate    STAR BAKER
    ##  6      5       6 Chetna  STAR BAKER
    ##  7      5       7 Richard STAR BAKER
    ##  8      5       8 Richard STAR BAKER
    ##  9      5       9 Richard STAR BAKER
    ## 10      5      10 Nancy   WINNER    
    ## # ℹ 50 more rows

We can see predictability in Nadiya (in season 6) and Candice (in season
7) who won multiple star baker awards and were ultimately crowned the
winner. However, in season 5, Nancy won the contest despite winning only
one star baker award (as compared to Richard who won 5 star baker
awards).

Viewership Data

``` r
viewers <- read_csv("./data/viewers.csv", na = c("NA", "",".")) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
    ) %>% 
    mutate(series = factor(series, levels = as.character(1:10))) %>% 
    arrange(series) %>% 
    relocate(series, episode)
```

    ## Rows: 10 Columns: 11
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (11): Episode, Series 1, Series 2, Series 3, Series 4, Series 5, Series ...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
head(viewers, 10)
```

    ## # A tibble: 10 × 3
    ##    series episode viewers
    ##    <fct>    <dbl>   <dbl>
    ##  1 1            1    2.24
    ##  2 1            2    3   
    ##  3 1            3    3   
    ##  4 1            4    2.6 
    ##  5 1            5    3.03
    ##  6 1            6    2.75
    ##  7 1            7   NA   
    ##  8 1            8   NA   
    ##  9 1            9   NA   
    ## 10 1           10   NA

Average Viewership

``` r
s1_average_viewership = viewers %>% 
  filter(series == 1) %>% 
  pull(viewers) %>% 
  mean(na.rm = TRUE) 

s5_average_viewership = viewers %>% 
  filter(series == 5) %>% 
  pull(viewers) %>% 
  mean(na.rm = TRUE) 

s1_average_viewership
```

    ## [1] 2.77

``` r
s5_average_viewership
```

    ## [1] 10.0393

The average viewership is 2.77 for season 1 and 10.0393 for season 5.
