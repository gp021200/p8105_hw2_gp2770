---
title: "p8105_hw2_gp2770"
author: "Gokul Pareek"
date: "2024-10-03"
output: github_document
---

I'm an R Markdown document!

# Problem 1

Reading and Cleaning the Data

```{r}
library (tidyverse)

nyc_transit_data <- read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",col_types= cols(Route8 = "c", Route9 = "c",Route10 = "c",Route11 = "c")) %>%   janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude,route1:route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

nyc_transit_data

```

The resulting dataset contains information about each entrance and exit for each subway station in NYC, including details such as the subway line, station name, geographic coordinates, routes served, entrance type, and ADA compliance status. Till now, I have standardized the variable names by converting them to lower snake case, selected and retained the relevant variables, and recoded the entry variable from a character class with "YES" and "NO" values to a logical class with "TRUE" and "FALSE" values. The dataset currently has 1,868 rows and 19 columns. However, the data is not yet tidy, as the multiple columns for route numbers (routes 1 through 11) represent values themselves, rather than being captured as a single variable.

Finding the number of distinct stations

```{r}

nrow(distinct(nyc_transit_data, line, station_name))

```

There are 465 distinct stations.

ADA compliant stations

```{r}

nyc_transit_data %>% 
  filter(ada == TRUE) %>% 
  distinct(line, station_name) %>% 
  nrow()

```

Out of the 465 distinct stations, 84 stations are ADA compliant.

Proportion of station entrances/exits without vending that allow entrance

```{r}

without_vending <- nyc_transit_data %>% 
                    filter(vending == "NO") %>%
                    filter(entry == TRUE) %>%  
                    nrow()

with_vending <- nyc_transit_data %>% 
                  filter(vending == "NO") %>%
                  nrow()

without_vending / with_vending

```

0.377 is the proportion of station entrances/exits without vending that allow entrances.

Reformatting the data to make route number and route name distinct variables

```{r}

nyc_transit_reformat_data <- nyc_transit_data %>%
  pivot_longer(route1:route11, 
               names_to = "route_number", 
               values_to = "route_name")

nyc_transit_reformat_data

```

Distinct stations that serve the A train

```{r}

nyc_transit_reformat_data %>% 
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()

```

60 distinct stations serve the A train.

A train serving stations that are ADA compliant

```{r}

nyc_transit_reformat_data %>% 
  filter(ada == TRUE) %>%  
  filter(route_name == "A") %>% 
  distinct(line, station_name) %>% 
  nrow()
```

Of the 60 stations that serve the A train, 17 stations are ADA compliant.

# Problem 2

Reading and Cleaning the Mr. Trash Wheel sheet

```{r}

library(readxl)

mr_trash_wheel_data <- read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel",range =  cell_cols("A:N"), col_names = TRUE, skip = 1) %>%
  janitor::clean_names() %>%
  rename(
    collection_month = month,
    collection_year = year,
    plastic_bottles_collected = plastic_bottles,
    polystyrene_collected = polystyrene,
    cigarette_butts_collected = cigarette_butts,
    sports_balls_collected = sports_balls,
    glass_bottles_collected = glass_bottles,
    wrappers_collected = wrappers,
    plastic_bags_collected = plastic_bags
    )%>%
  filter(!is.na(dumpster)) %>%
  mutate(
    sports_balls_collected = as.integer(round(sports_balls_collected)),
    trash_wheel = "Mr. Trash Wheel"
  )

```

Reading and Cleaning the Professor Trash Wheel

```{r}

professor_trash_wheel_data <-  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel", range = cell_cols("A:M"), col_names = TRUE, skip = 1) %>%
  janitor::clean_names() %>%
  rename(
    collection_month = month,
    collection_year = year,
    plastic_bottles_collected = plastic_bottles,
    polystyrene_collected = polystyrene,
    cigarette_butts_collected = cigarette_butts,
    glass_bottles_collected = glass_bottles,
    wrappers_collected = wrappers,
    plastic_bags_collected = plastic_bags
    )%>%
  filter(!is.na(dumpster)) %>%
  mutate(trash_wheel = "Professor Trash Wheel"
  )

```

Reading and Cleaning the Gwynnda Trash Wheel

```{r}

gwynnda_trash_wheel_data <-  read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel", range = cell_cols("A:L"), col_names = TRUE, skip = 1) %>%
  janitor::clean_names() %>%
  rename(
    collection_month = month,
    collection_year = year,
    plastic_bottles_collected = plastic_bottles,
    polystyrene_collected = polystyrene,
    cigarette_butts_collected = cigarette_butts,
    wrappers_collected = wrappers,
    plastic_bags_collected = plastic_bags
    )%>%
  filter(!is.na(dumpster)) %>%
  mutate(trash_wheel = "Gwynnda Trash Wheel"
  )

```

Combining the three datasets

```{r}

mr_trash_wheel_data <- mr_trash_wheel_data %>%
  mutate(collection_year = as.character(collection_year))

professor_trash_wheel_data <- professor_trash_wheel_data %>%
  mutate(collection_year = as.character(collection_year))

gwynnda_trash_wheel_data <- gwynnda_trash_wheel_data %>%
  mutate(collection_year = as.character(collection_year))

combined_trash_wheel_data <- bind_rows(mr_trash_wheel_data, 
                                       professor_trash_wheel_data, 
                                       gwynnda_trash_wheel_data)

combined_trash_wheel_data

```

The combined Trash Wheel dataset contains a total of `r nrow(combined_trash_wheel_data)` observations, consolidating information from three different Trash Wheels: Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda. Key variables include collection_month, collection_year, weight_tons which is the weight of trash collected by each dumpster, and waste types like cigarette_butts_collected and plastic_bags_collected.

Total weight of trash collected by Professor Trash Wheel

```{r}

total_professor_trash_wheel_weight <- combined_trash_wheel_data %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  pull(weight_tons) %>%
  sum(na.rm = TRUE)

total_professor_trash_wheel_weight

```

The total weight of trash collected by Professor Trash Wheel was 246.74 tons.

Total number of cigarette butts collected by Gwynnda in June of 2022

```{r}

total_cigarette_butts_gwynnda_june_2022 <- combined_trash_wheel_data %>%
  filter(trash_wheel == "Gwynnda Trash Wheel" & collection_month == "June" & collection_year == 2022) %>%
  pull(cigarette_butts_collected) %>%
  sum(na.rm = TRUE)

total_cigarette_butts_gwynnda_june_2022

```

The total number of cigarette butts collected by Gwynnda in June of 2022 was 18120.

# Problem 3

Importing and cleaning the information about individual bakers, their bakes and their performances.

```{r}

bakers <- read_csv("./data/bakers.csv", na = c("NA", "",".")) %>% 
  janitor::clean_names() %>% 
  separate(col = baker_name, into = c("baker", "baker_last_name"), sep = " ")

bakes <- read_csv("./data/bakes.csv", na = c("NA", "",".")) %>% 
  janitor::clean_names() %>% 
  mutate(baker = ifelse(baker == '"Jo"', "Joanne", baker))

results <- read_csv("./data/results.csv", skip = 2, na = c("NA", "",".")) %>% 
  janitor::clean_names()

```

Checking for completeness and correctness across datasets.

```{r}

missing_bakes = anti_join(bakers, bakes, 
                              by = c("baker" = "baker", "series"))

missing_results = anti_join(bakers, results, 
                                by = c("baker" = "baker", "series"))

missing_bakes_results = anti_join(bakes, results, 
                                          by = c("baker", "series", "episode"))

```

Creating a single final dataset and exporting the results as a CSV.

```{r}

final_dataset = left_join(results, bakes, by = c("series", "episode", "baker")) %>% 
                  left_join(bakers, by = c("series", "baker"))

final_dataset <- final_dataset %>%
  relocate(series, episode, baker, baker_last_name, baker_age, baker_occupation, hometown, signature_bake, technical, show_stopper, result)

write_csv(final_dataset, "./data/final_gbbo_dataset.csv")
```

In the data cleaning process, I imported three datasets of the Great British Bake Off â€”bakers, bakes, and results while standardizing their column names using janitor::clean_names(). I separated the baker_name into distinct first and last names and modified specific values for consistency (changing "Jo" to "Joanne" in the bakes dataset). I skipped unnecessary rows in the results dataset and checked for completeness using anti_join() to identify missing matches across the datasets. The final dataset was created by merging the three datasets based on common columns and relocating the columns for clarity. Finally, I used write_csv() to export the cleaned and combined dataset as a CSV file named final_gbbo_dataset.csv in the data directory. The final dataset gives a comprehensive overview of the Great British Bake Off (GBBO) competition, combining individual baker details with their bakes and performance results. Important variables are like series, episode, baker and show_stopper are relocated in order to conduct smooth analysis on the consolidated dataset.

Creating a reader-friendly table for star baker/winner of each episode from S5 to S10.

```{r}

star_bakers_or_winners <- final_dataset %>%
  filter(series > 4) %>%  
  select(series, episode, baker, result) %>%
  filter(result %in% c("STAR BAKER", "WINNER")) %>%
  arrange(series, episode) 

star_bakers_or_winners
```

We can see predictability in Nadiya (in season 6) and Candice (in season 7) who won multiple star baker awards and were ultimately crowned the winner. However, in season 5, Nancy won the contest despite winning only one star baker award (as compared to Richard who won 5 star baker awards).

Viewership Data

```{r}

viewers <- read_csv("./data/viewers.csv", na = c("NA", "",".")) %>% 
  janitor::clean_names() %>% 
  pivot_longer(
    cols = series_1:series_10,
    names_to = "series",
    values_to = "viewers",
    names_prefix = "series_"
    ) %>% 
    mutate(series = factor(series, levels = as.character(1:10))) %>% 
    arrange(series) %>% 
    relocate(series, episode)

head(viewers, 10)
```

Average Viewership

```{r}

s1_average_viewership = viewers %>% 
  filter(series == 1) %>% 
  pull(viewers) %>% 
  mean(na.rm = TRUE) 

s5_average_viewership = viewers %>% 
  filter(series == 5) %>% 
  pull(viewers) %>% 
  mean(na.rm = TRUE) 

s1_average_viewership
s5_average_viewership
  
```

The average viewership is 2.77 for season 1 and 10.0393 for season 5.
